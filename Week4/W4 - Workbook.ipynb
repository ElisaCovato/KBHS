{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a31212a",
   "metadata": {},
   "source": [
    "# NLP and knowledge graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a1070f",
   "metadata": {},
   "source": [
    "**Knowledge graphs** allow to represent information in a structured manner, capturing relationships between entities. On the other side **NLP** focuses on understanding and processing human language. So, what about combining them to create an efficient way for extracting and analysing information?\n",
    "\n",
    "\n",
    "## Your challenge\n",
    "You have been tasked with creating a knowledge graph that stores and infer information from a large document.\n",
    "\n",
    "#### Requirements\n",
    "In your group, you should:\n",
    "- read and process the text in the provided document;\n",
    "- extract entities and relationships present within it;\n",
    "- store this information in a knowledge graph;\n",
    "- and visualize the graph. \n",
    "\n",
    "You can utilise the knowledge and skills acquired from other modules to accomplish this task effectively. \n",
    "\n",
    "_Your graph will be huge and very complex, so you might want to plot only a 'piece of knowledge' maybe just related to a specific node or a relationship_.\n",
    "\n",
    "#### Data\n",
    "The dataset, named `ai_wiki_page.txt`, is a text file containing the textual content extracted from the [Wikipedia page dedicated to Artificial Intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence). Your task is to transform the information contained in such document into a knowledge graph.\n",
    "\n",
    "The directed graph to construct is made of triplets: **(head, relation, tail)**. In the case of text mining, these tripets are usually of the type **(subject, verb, object)**. For example, 'Paris is the capital of France' can be translated into (Paris, is_capital, France), where Paris and France are _nodes_ and is_capital is the connecting _edge_.\n",
    "\n",
    "#### Libraries\n",
    "You can use whatever library will help you to achieve your task. **Pandas** (for general data mining), **spaCy** (for NLP related work) and **networkX** (for graph visualisation) are recommended. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408dbe9e",
   "metadata": {},
   "source": [
    "You are now ready to develop your solution. Below there are some hints that you can use at any point if you get stuck or want to check your process. \n",
    "\n",
    "**Good luck!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a778484",
   "metadata": {},
   "source": [
    "### Hints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6c7973",
   "metadata": {},
   "source": [
    "#### Hint 1A - text processing\n",
    "<details>\n",
    "  <summary>Click here to show the hint</summary>\n",
    "  \n",
    "  To create your knowledge graph you will need to extract sentences from the text document.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a426c15a",
   "metadata": {},
   "source": [
    "#### Hint 1B - text processing\n",
    "<details>\n",
    "  <summary>Click here to show the hint</summary>\n",
    "  \n",
    "  Your document contains lots of sentences. Try to reduce them considering only the sentences with exactly 1 subject and 1 object.    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d7f4b5",
   "metadata": {},
   "source": [
    "#### Hint 2 - entities extraction\n",
    "<details>\n",
    "  <summary>Click here to show the hint</summary>\n",
    "  \n",
    "  The main idea is to extract the subject and the object from each sentence. However an entity (subject/object) can span across multiple words, e.g., 'artificial intelligence' . You can easily extract a single entity using parts of speech (POS) tags, but these are not sufficient when an entity is made of multiple words. In the case of 'Aritificial Intelligence' only 'intelligence' would count as noun. Hence, it might be helpful creating a function that uses both POS and dependency tags (DEP) to find multiple words entities. \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eee019b",
   "metadata": {},
   "source": [
    "#### Hint 3 - relation extraction\n",
    "<details>\n",
    "  <summary>Click here to show the hint</summary>\n",
    "  \n",
    "  To extract relations/verbs, you can use spaCyâ€™s rule-based matching: https://spacy.io/usage/rule-based-matching/\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48bf313",
   "metadata": {},
   "source": [
    "#### Hint 4 - KG\n",
    "<details>\n",
    "  <summary>Click here to show the hint</summary>\n",
    "  \n",
    "  Once you have your subjects/source, objetcs/targets, verbs/relationships triplets, you can construct your direct graph with networkX. Try to store your triplets into a dataframe and construct your graph using `nx.from_pandas_edgelist`. \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec3db26",
   "metadata": {},
   "source": [
    "## Your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6953fd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
