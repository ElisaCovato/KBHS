{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a31212a",
   "metadata": {},
   "source": [
    "# Neuro-symbolic AI - Ontologies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a1070f",
   "metadata": {},
   "source": [
    "This workbook explores the concepts of **hybrid intelligent systems**, in particular of how to combine a knowledge-base structure with a neural network, in other words, how to create a **neuro-symbolic** solution. \n",
    "\n",
    "\n",
    "Throughout this notebook, you will work  simple hybrid systems, using ontologies and, of course, neural networks. You will find some guided examples to aid your understanding, and some exercises for you to implement on your own.\n",
    "\n",
    "#### Content:\n",
    "* [SenticNet - Sentiment Ontologies](#senticnet)\n",
    "    * [Getting started](#senticnet-start)\n",
    "    * [Exercise: sentiment analysis](#senticnet-ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954b0b6e",
   "metadata": {},
   "source": [
    "## SenticNet - Sentiment Ontologies <a class=\"anchor\" id=\"senticnet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559750e7",
   "metadata": {},
   "source": [
    "**[SenticNet](https://sentic.net)** is a publicly available, commonsense-based, knowledge resource for explainable sentiment analysis. It is created through a combination of natural language processing, machine learning, and human annotation. The latest version, [SenticNet7](https://sentic.net/senticnet-7.pdf) contains 300,000 concepts organised in a **ontology**, a structured, formalised semantic network, with precise language, nodes and edges (refer to Week3 learning material for more details).\n",
    "\n",
    "The picture below shows the graph structure used to decide the sentiment expressed by specific concepts.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c143482b",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"senticnet7-structure.jpg\" alt=\"SenticNet strcuture\" style=\"width: 800px;\"/>\n",
    "<figcaption style=\"text-align:center;font-style:italic\">(from \"Cambria, E. et al. â€“ SenticNet 7: A Commonsense-based Neurosymbolic\n",
    "AI Framework for Explainable Sentiment Analysis\" (2022) </figcaption>    \n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dc418b",
   "metadata": {},
   "source": [
    "The latest ontology version can be freely downloaded in  [80 different languages](https://sentic.net/downloads/), or used through [SenticNet' APIs](https://sentic.net/api/). To visualise the full ontologies (and their schema) you can upload them to [WebVOWL](https://service.tib.eu/webvowl/), or use the **owlready2** python library introduced in Week3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88e1553",
   "metadata": {},
   "source": [
    "For each of the 300,000 natural language concepts in SenticNet7, the knowledge base provides:\n",
    "\n",
    "* **semantic**: other concepts associated (=semantically-related) to the concept in question\n",
    "* **sentic**: emotional categorisation values based on four affective dimension\n",
    "* **polarity**: a numerical value ranging from -1 to 1, with -1 representing very negative sentiment, 0 indicating neutral sentiment, and 1 representing very positive sentiment.\n",
    "\n",
    "These information can be accessed through the [SenticNet downloads or API](https://sentic.net/downloads/). For convenience, we will access this through the sencticnet python library.\n",
    "\n",
    "(_Note: the python library is based on SenticNet6_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b85113",
   "metadata": {},
   "source": [
    "### Getting started <a class=\"anchor\" id=\"senticnet-start\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d42d1a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install senticnet\n",
    "\n",
    "from senticnet.senticnet import SenticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "440236cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create the senticnet knowledge base\n",
    "sn = SenticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cab6c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'polarity_label': 'positive',\n",
       " 'polarity_value': '0.824',\n",
       " 'sentics': {'introspection': '0.925',\n",
       "  'temper': '0',\n",
       "  'attitude': '0.722',\n",
       "  'sensitivity': '0'},\n",
       " 'moodtags': ['#joy', '#pleasantness'],\n",
       " 'semantics': ['encyclopedism',\n",
       "  'erudition',\n",
       "  'scholarship',\n",
       "  'learnedness',\n",
       "  'eruditeness']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query the KB about the concept of 'learning'\n",
    "\n",
    "sn.concept('learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbbacbc",
   "metadata": {},
   "source": [
    "Using the SenticNet KB we have inferenced the following facts about 'learning':\n",
    "\n",
    "* **semantic**: the other concepts associated to learning are: 'encyclopedism', 'erudition', 'scholarship', 'learnedness', 'eruditeness'\n",
    "* **sentic**: the four affective dimensions  have the following values:\n",
    "    * introspection: 0.925\n",
    "    * temper: 0\n",
    "    * attitude: 0.722\n",
    "    * sensitivity: 0\n",
    "* **polarity**: the concept is labelled as positive, having a value of 0.824"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b266cf16",
   "metadata": {},
   "source": [
    "Let's now uses this knowledge base to create a neuro-symbolic solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baddee75",
   "metadata": {},
   "source": [
    "### Exercise - sentiment analysis <a class=\"anchor\" id=\"senticnet-ex\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf8a271",
   "metadata": {},
   "source": [
    "We are going to use the SenticNet KB to create an hybrid system for sentiment analysis. \n",
    "\n",
    "For this exercise we are going to use the [IMDB dataset of movie reviews](https://ai.stanford.edu/~amaas/data/sentiment/). You should be familiar with this dataset from other modules.\n",
    "\n",
    "Our final goal is to create a model capable of predicting the overall sentiment (positive/negative) of movies.  The hybrid system will be of type **Neuro | Symbolic** (see this week slides for more details): symbolic part and neural network perform complimentary tasks in a pipeline. In the specific we will:\n",
    "\n",
    "* pre-process our dataset\n",
    "* (**symbolic**) for each concept in the review, inference the polarity score using the SenticNet KB (this wil create an array of numerical values for each review)\n",
    "* (**neural**) train a simple neural network with the polarity scores previously generated \n",
    "* use the model for predictions\n",
    "\n",
    "\n",
    "**Note: The purpose of this exercise is not to get a perfect, accurate trained model, but mostly understanding the general idea of combining the two AI paradigms into one solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fe02c6",
   "metadata": {},
   "source": [
    "**Pre-process**\n",
    "\n",
    "Let's start by pre-processing our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30a0e19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize import word_tokenize \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27af163c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29266</th>\n",
       "      <td>Eddie Murphy plays Chandler Jarrell, a man who...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44854</th>\n",
       "      <td>It has been years since I have been privileged...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24313</th>\n",
       "      <td>If Fassbinder has made a worse film, I sure do...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38233</th>\n",
       "      <td>To me A Matter of Life and Death is just that-...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33454</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;I just bought this movie on DVD an...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "29266  Eddie Murphy plays Chandler Jarrell, a man who...  positive\n",
       "44854  It has been years since I have been privileged...  positive\n",
       "24313  If Fassbinder has made a worse film, I sure do...  negative\n",
       "38233  To me A Matter of Life and Death is just that-...  positive\n",
       "33454  <br /><br />I just bought this movie on DVD an...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "imdb_data = pd.read_csv('./imdb_data.csv')\n",
    "\n",
    "# show a sample of rows\n",
    "imdb_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f78d4198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset quick description\n",
    "imdb_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fcf519d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           review\n",
       "sentiment        \n",
       "negative    25000\n",
       "positive    25000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of reviews for each label\n",
    "imdb_data.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3177fc82",
   "metadata": {},
   "source": [
    "We are going to perform the following pre-processing steps:\n",
    "\n",
    "* convert the sentiment label to a binary value\n",
    "* tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01898042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert sentiments to binary 0/1\n",
    "imdb_data['sentiment'] = pd.get_dummies(imdb_data['sentiment'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca5564",
   "metadata": {},
   "source": [
    "**Task 1 (optional)**\n",
    "\n",
    "The dataset needs some cleaning. Use your knowledge of text pre-processing to:\n",
    "\n",
    "\n",
    "- convert text to lower case\n",
    "- remove html tags\n",
    "- remove punctuation\n",
    "- remove stop words (hint: use [`from nltk.corpus import stopwords`](https://stackoverflow.com/questions/29523254/python-remove-stop-words-from-pandas-dataframe))\n",
    "\n",
    "(Feel free to add any other pre-processing steps you find appropriate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4719cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write here your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b36fe4",
   "metadata": {},
   "source": [
    "Let's tokenise the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2960ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenise the dataset\n",
    "imdb_data['review_tokens'] = imdb_data['review'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97ce479",
   "metadata": {},
   "source": [
    "The pre-processed dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2483d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12804</th>\n",
       "      <td>This movie is hilarious! I watched it with my ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[This, movie, is, hilarious, !, I, watched, it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14476</th>\n",
       "      <td>I just watched Atoll K-Laurel and Hardy's last...</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, just, watched, Atoll, K-Laurel, and, Hardy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27487</th>\n",
       "      <td>After looking at monkeys (oops apes) for more ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[After, looking, at, monkeys, (, oops, apes, )...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34662</th>\n",
       "      <td>This film fails on every count. For a start it...</td>\n",
       "      <td>0</td>\n",
       "      <td>[This, film, fails, on, every, count, ., For, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11535</th>\n",
       "      <td>A kind of road movie in old-fashioned trains i...</td>\n",
       "      <td>1</td>\n",
       "      <td>[A, kind, of, road, movie, in, old-fashioned, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment  \\\n",
       "12804  This movie is hilarious! I watched it with my ...          1   \n",
       "14476  I just watched Atoll K-Laurel and Hardy's last...          0   \n",
       "27487  After looking at monkeys (oops apes) for more ...          0   \n",
       "34662  This film fails on every count. For a start it...          0   \n",
       "11535  A kind of road movie in old-fashioned trains i...          1   \n",
       "\n",
       "                                           review_tokens  \n",
       "12804  [This, movie, is, hilarious, !, I, watched, it...  \n",
       "14476  [I, just, watched, Atoll, K-Laurel, and, Hardy...  \n",
       "27487  [After, looking, at, monkeys, (, oops, apes, )...  \n",
       "34662  [This, film, fails, on, every, count, ., For, ...  \n",
       "11535  [A, kind, of, road, movie, in, old-fashioned, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3597a3",
   "metadata": {},
   "source": [
    "**Symbolic: inference polarity**\n",
    "\n",
    "For each review, we want to compute the polarity for all the concepts/tokens contained in the review. Let's do this for one single review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0724c397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original review: One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n",
      "\n",
      "Sentiment: 1\n",
      "\n",
      "Tokens: ['One', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', '1', 'Oz', 'episode', 'you', \"'ll\", 'be', 'hooked', '.', 'They', 'are', 'right', ',', 'as', 'this', 'is', 'exactly', 'what', 'happened', 'with', 'me.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'The', 'first', 'thing', 'that', 'struck', 'me', 'about', 'Oz', 'was', 'its', 'brutality', 'and', 'unflinching', 'scenes', 'of', 'violence', ',', 'which', 'set', 'in', 'right', 'from', 'the', 'word', 'GO', '.', 'Trust', 'me', ',', 'this', 'is', 'not', 'a', 'show', 'for', 'the', 'faint', 'hearted', 'or', 'timid', '.', 'This', 'show', 'pulls', 'no', 'punches', 'with', 'regards', 'to', 'drugs', ',', 'sex', 'or', 'violence', '.', 'Its', 'is', 'hardcore', ',', 'in', 'the', 'classic', 'use', 'of', 'the', 'word.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'It', 'is', 'called', 'OZ', 'as', 'that', 'is', 'the', 'nickname', 'given', 'to', 'the', 'Oswald', 'Maximum', 'Security', 'State', 'Penitentary', '.', 'It', 'focuses', 'mainly', 'on', 'Emerald', 'City', ',', 'an', 'experimental', 'section', 'of', 'the', 'prison', 'where', 'all', 'the', 'cells', 'have', 'glass', 'fronts', 'and', 'face', 'inwards', ',', 'so', 'privacy', 'is', 'not', 'high', 'on', 'the', 'agenda', '.', 'Em', 'City', 'is', 'home', 'to', 'many', '..', 'Aryans', ',', 'Muslims', ',', 'gangstas', ',', 'Latinos', ',', 'Christians', ',', 'Italians', ',', 'Irish', 'and', 'more', '....', 'so', 'scuffles', ',', 'death', 'stares', ',', 'dodgy', 'dealings', 'and', 'shady', 'agreements', 'are', 'never', 'far', 'away.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'I', 'would', 'say', 'the', 'main', 'appeal', 'of', 'the', 'show', 'is', 'due', 'to', 'the', 'fact', 'that', 'it', 'goes', 'where', 'other', 'shows', 'would', \"n't\", 'dare', '.', 'Forget', 'pretty', 'pictures', 'painted', 'for', 'mainstream', 'audiences', ',', 'forget', 'charm', ',', 'forget', 'romance', '...', 'OZ', 'does', \"n't\", 'mess', 'around', '.', 'The', 'first', 'episode', 'I', 'ever', 'saw', 'struck', 'me', 'as', 'so', 'nasty', 'it', 'was', 'surreal', ',', 'I', 'could', \"n't\", 'say', 'I', 'was', 'ready', 'for', 'it', ',', 'but', 'as', 'I', 'watched', 'more', ',', 'I', 'developed', 'a', 'taste', 'for', 'Oz', ',', 'and', 'got', 'accustomed', 'to', 'the', 'high', 'levels', 'of', 'graphic', 'violence', '.', 'Not', 'just', 'violence', ',', 'but', 'injustice', '(', 'crooked', 'guards', 'who', \"'ll\", 'be', 'sold', 'out', 'for', 'a', 'nickel', ',', 'inmates', 'who', \"'ll\", 'kill', 'on', 'order', 'and', 'get', 'away', 'with', 'it', ',', 'well', 'mannered', ',', 'middle', 'class', 'inmates', 'being', 'turned', 'into', 'prison', 'bitches', 'due', 'to', 'their', 'lack', 'of', 'street', 'skills', 'or', 'prison', 'experience', ')', 'Watching', 'Oz', ',', 'you', 'may', 'become', 'comfortable', 'with', 'what', 'is', 'uncomfortable', 'viewing', '....', 'thats', 'if', 'you', 'can', 'get', 'in', 'touch', 'with', 'your', 'darker', 'side', '.']\n",
      "\n",
      "Polarity: {'hooked': '0.9', 'brutality': '-1.0', 'violence': '-0.92', 'faint': '0.9', 'timid': '-0.74', 'pulls': '0.9', 'drugs': '-0.64', 'sex': '0.747', 'hardcore': '-0.08', 'classic': '0.161', 'nickname': '-0.16', 'prison': '-0.83', 'privacy': '-0.17', 'high': '0.085', 'death': '-0.83', 'dodgy': '-0.45', 'shady': '-0.85', 'main': '0.775', 'appeal': '0.232', 'dare': '-0.12', 'forget': '-0.7', 'charm': '0.9', 'romance': '-0.88', 'mess': '-0.81', 'nasty': '-0.81', 'surreal': '-0.91', 'ready': '0.9', 'taste': '0.366', 'injustice': '-0.83', 'nickel': '0.943', 'kill': '-0.18', 'mannered': '0.9', 'lack': '-0.77', 'comfortable': '0.76', 'uncomfortable': '-0.00', 'touch': '0.9', 'darker': '-0.82'}\n"
     ]
    }
   ],
   "source": [
    "rvw = imdb_data.iloc[0]\n",
    "rvw_tokens = imdb_data['review_tokens'].iloc[0]\n",
    "\n",
    "rvw_polarity = dict()\n",
    "\n",
    "for concept in rvw_tokens:\n",
    "    # get the polarity score from SenticNet\n",
    "    try:\n",
    "        polarity_score = sn.polarity_value(concept)\n",
    "        rvw_polarity[concept]= polarity_score\n",
    "    # ignore tokens not found in SenticNet\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print('Original review:', rvw['review'])\n",
    "print('\\nSentiment:', rvw['sentiment'])\n",
    "print('\\nTokens:', rvw_tokens)\n",
    "print('\\nPolarity:', rvw_polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1918d39",
   "metadata": {},
   "source": [
    "We want to train our LSTM with the numerical values from the polarity dictionary, hence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81766dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['0.9', '-1.0', '-0.92', '0.9', '-0.74', '0.9', '-0.64', '0.747', '-0.08', '0.161', '-0.16', '-0.83', '-0.17', '0.085', '-0.83', '-0.45', '-0.85', '0.775', '0.232', '-0.12', '-0.7', '0.9', '-0.88', '-0.81', '-0.81', '-0.91', '0.9', '0.366', '-0.83', '0.943', '-0.18', '0.9', '-0.77', '0.76', '-0.00', '0.9', '-0.82'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvw_polarity.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e99e82",
   "metadata": {},
   "source": [
    "Let's now inference the polarity for all the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462f559e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This function gets an array of tokens and returns an array of polarity scores\n",
    "\n",
    "def get_polarity_scores(tokens):\n",
    "    polarity_scores = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        # Get the polarity score from SenticNet\n",
    "        try:\n",
    "            polarity_scores.append(sn.polarity_value(token))\n",
    "        # Ignore tokens not found in SenticNet\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return polarity_scores\n",
    "\n",
    "\n",
    "# apply function to the dataset\n",
    "imdb_data['pol_scores'] = imdb_data['review_tokens'].apply(lambda x : get_polarity_scores(x))\n",
    "\n",
    "imdb_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441012da",
   "metadata": {},
   "source": [
    "We are now ready to train our LSTM model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a199a28a",
   "metadata": {},
   "source": [
    "**Neural : simple NN model**\n",
    "\n",
    "We start by dividing the dataset into train, validation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35105eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = polarity scores, y = sentiment labels\n",
    "X = imdb_data['pol_scores'].to_list()\n",
    "y = imdb_data['sentiment'].to_numpy()\n",
    "\n",
    "# all the arrays in X have different length, so we need to 'pad' them\n",
    "X = pad_sequences(X, padding='post', dtype=float)\n",
    "\n",
    "# split dataset: train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# split dataset: train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf217b4",
   "metadata": {},
   "source": [
    "Create the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b962404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bab405",
   "metadata": {},
   "source": [
    "Train the model:\n",
    "\n",
    "(**Accuracy will NOT be high!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0aa2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "\n",
    "results = model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5bf04a",
   "metadata": {},
   "source": [
    "**Task 2 (optional)**\n",
    "\n",
    "Evaluate the model on:\n",
    "- validation set\n",
    "- test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8134aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write here your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd08fae",
   "metadata": {},
   "source": [
    "As you can observe, the accuracy is pretty low, this can be due to different factors (in primis, the simplicity of the model). Try to change the Neural Network structure. Would a RNN/LSTM structure be more efficient?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
